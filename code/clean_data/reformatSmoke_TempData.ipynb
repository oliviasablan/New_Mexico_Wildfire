{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making large dataset of population-weight ZIP code smoke estimates and population-weight temperature data\n",
    "##### Also need to \"melt\" the dataframe so the Zips are separate rows instead of column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with Kate O'Dell's product\n",
    "# Read in all years of files for smoke and then total PM2.5\n",
    "inputfiles = glob.glob('C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KateZip/nm_smoke*.csv')\n",
    "df_from_each_file = (pd.read_csv(f) for f in inputfiles)\n",
    "smoke = pd.concat(df_from_each_file,sort=False)\n",
    "meltsmoke= smoke.melt(id_vars=['Date'],var_name='Zip',value_name='smokepm25')\n",
    "\n",
    "inputfiles = glob.glob('C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KateZip/nm_total*.csv')\n",
    "df_from_each_file = (pd.read_csv(f) for f in inputfiles)\n",
    "total = pd.concat(df_from_each_file,sort=False)\n",
    "melttotal= total.melt(id_vars=['Date'],var_name='Zip',value_name='totalpm25')\n",
    "\n",
    "mergedZip= pd.merge(meltsmoke, melttotal, on = ['Date', 'Zip'])\n",
    "mergedZip.to_csv('C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KateZip/AllZipSmoke_Total_os.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, do the same for Bonne Ford's smoke product\n",
    "# This product is only for 2022 so we don't need to \"glob\" to read it a bunch of files\n",
    "smoke = pd.read_csv(\"C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/nm_smoke_zipcode_2022_final.csv\")\n",
    "total = pd.read_csv(\"/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/nm_totalpm_zipcode_2022_final.csv\")\n",
    "melttotal = total.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'totalpm25')\n",
    "meltsmoke= smoke.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'smokepm25')\n",
    "alltogether = pd.merge(meltsmoke, melttotal, on = ['Date', 'Zip'])\n",
    "alltogether.to_csv('/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/bigPurpleAirZip_os.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Bonne Ford's other smoke product that uses Kate O'Dell's variogram parameters (vgp) for kriging\n",
    "smoke = pd.read_csv(\"C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/nm_smoke_zipcode_2022_final_KOvgp.csv\")\n",
    "total = pd.read_csv(\"/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/nm_totalpm_zipcode_2022_final_KOvgp.csv\")\n",
    "melttotal = total.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'totalpm25')\n",
    "meltsmoke= smoke.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'smokepm25')\n",
    "alltogether = pd.merge(meltsmoke, melttotal, on = ['Date', 'Zip'])\n",
    "alltogether.to_csv('/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/BonneZip/bigPurpleAirZip_os_KOvgp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, repeated for Kamal's smoke product\n",
    "smoke = pd.read_csv(\"C:/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KamalZip/BI_PM25_TOT_AVG_FUSED_zipcode_new.csv\")\n",
    "smokemax = pd.read_csv(\"/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KamalZip/BI_PM25_TOT_MAX_FUSED_zipcode_new.csv\")\n",
    "total = pd.read_csv(\"/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KamalZip/Daily_PM25_TOT_AVG_FUSED_zipcode_new.csv\")\n",
    "totalmax = pd.read_csv(\"/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KamalZip/Daily_PM25_TOT_MAX_FUSED_zipcode_new.csv\")\n",
    "\n",
    "meltsmoke = smoke.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'smokepm25')\n",
    "meltsmokemax = smokemax.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'maxsmokepm25')\n",
    "melttotal = total.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'totalpm25')\n",
    "melttotalmax= totalmax.melt(id_vars = ['Date'], var_name = 'Zip', value_name= 'maxtotalpm25')\n",
    "\n",
    "merge1 = pd.merge(meltsmoke, meltsmokemax, on = ['Date', 'Zip'])\n",
    "merge2 = pd.merge(merge1, melttotal, on = ['Date', 'Zip'])\n",
    "alltogether = pd.merge(merge2, melttotalmax, on = ['Date', 'Zip'])\n",
    "\n",
    "alltogether.to_csv('/Users/olivia.sablan/OneDrive - State of New Mexico/Documents/Data/smoke/KamalZip/bigKamalZip_os.csv')\n",
    "\n",
    "merge3 = pd.merge(meltsmoke, melttotal , on = ['Date', 'Zip'])\n",
    "merge4 = pd.merge(meltsmokemax, melttotalmax , on = ['Date', 'Zip'])\n",
    "\n",
    "merge3.to_csv('../Data/smoke/KamalZip/Kamal_average_reformat_all_OS.csv')\n",
    "merge4 = merge4.rename(columns = {'maxsmokepm25': 'smokepm25'})\n",
    "merge4.to_csv('../Data/smoke/KamalZip/Kamal_max_reformat_all_OS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in population-weight temp data from Florida State University\n",
    "poptemp = pd.read_csv('../Data/temp/max_temperature_zipcode_pop_weighted.csv')\n",
    "# The dates are formatted in days since the unix date (Jan 1 1970), but we know this data is from Jan 1, 2016 to Dece 31 2022 so we can make a list of those dates\n",
    "range = pd.date_range(start='1/1/2016', end='12/31/2022')\n",
    "# Rename the data column headers in this usable format\n",
    "newdates_temp = poptemp.iloc[:,1:].set_axis(range, axis=1)\n",
    "# Add back in the ZIP codes\n",
    "newdates_temp['Zip'] = poptemp['zipcode']\n",
    "# Melt the data so that columns are \"Date\", \"Zip\", and \"maxpoptemp\"\n",
    "melttemp = newdates_temp.melt(id_vars = ['Zip'], var_name = 'Date', value_name= 'maxpoptemp')\n",
    "# Reformat date to make pretty\n",
    "melttemp['Date'] = pd.to_datetime(melttemp['Date']).dt.date\n",
    "# Save dataframe\n",
    "melttemp.to_csv('../Data/temp/MaxPop_temp_OS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in population-weight heat index data from Florida State University\n",
    "poptemp = pd.read_csv('../Data/temp/max_HI_zipcode_pop_weighted.csv')\n",
    "# The dates are formatted in days since the unix date (Jan 1 1970), but we know this data is from Jan 1, 2016 to Dece 31 2022 so we can make a list of those dates\n",
    "range = pd.date_range(start='1/1/2016', end='12/31/2022')\n",
    "# Rename the data column headers in this usable format\n",
    "newdates_temp = poptemp.iloc[:,1:].set_axis(range, axis=1)\n",
    "# Add back in the ZIP codes\n",
    "newdates_temp['Zip'] = poptemp['zipcode']\n",
    "# Melt the data so that columns are \"Date\", \"Zip\", and \"maxpoptemp\"\n",
    "melttemp = newdates_temp.melt(id_vars = ['Zip'], var_name = 'Date', value_name= 'maxpopHI')\n",
    "# Reformat date to make pretty\n",
    "melttemp['Date'] = pd.to_datetime(melttemp['Date']).dt.date\n",
    "# Save dataframe\n",
    "melttemp.to_csv('../Data/temp/MaxPop_HI_OS.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
